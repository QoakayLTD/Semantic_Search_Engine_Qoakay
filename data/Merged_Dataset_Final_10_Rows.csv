indexId,paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,fieldsOfStudy/1,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name,authors/30/authorId,authors/30/name,authors/31/authorId,authors/31/name,authors/32/authorId,authors/32/name,authors/33/authorId,authors/33/name,authors/34/authorId,authors/34/name,authors/35/authorId,authors/35/name,authors/36/authorId,authors/36/name,authors/37/authorId,authors/37/name,authors/38/authorId,authors/38/name,authors/39/authorId,authors/39/name,fieldsOfStudy/2,fieldsOfStudy/3,authors/40/authorId,authors/40/name,authors/41/authorId,authors/41/name,authors/42/authorId,authors/42/name,authors/43/authorId,authors/43/name,authors/44/authorId,authors/44/name,authors/45/authorId,authors/45/name,authors/46/authorId,authors/46/name,authors/47/authorId,authors/47/name,authors/48/authorId,authors/48/name,authors/49/authorId,authors/49/name,authors/50/authorId,authors/50/name,authors/51/authorId,authors/51/name,authors/52/authorId,authors/52/name,authors/53/authorId,authors/53/name,authors/54/authorId,authors/54/name,authors/55/authorId,authors/55/name,authors/56/authorId,authors/56/name,authors/57/authorId,authors/57/name,authors/58/authorId,authors/58/name,authors/59/authorId,authors/59/name,authors/60/authorId,authors/60/name,authors/61/authorId,authors/61/name,authors/62/authorId,authors/62/name,authors/63/authorId,authors/63/name,authors/64/authorId,authors/64/name,authors/65/authorId,authors/65/name,authors/66/authorId,authors/66/name,authors/67/authorId,authors/67/name,authors/68/authorId,authors/68/name,authors/69/authorId,authors/69/name,authors/70/authorId,authors/70/name,authors/71/authorId,authors/71/name,authors/72/authorId,authors/72/name,authors/73/authorId,authors/73/name,authors/74/authorId,authors/74/name,authors/75/authorId,authors/75/name,authors/76/authorId,authors/76/name,authors/77/authorId,authors/77/name,authors/78/authorId,authors/78/name,authors/79/authorId,authors/79/name,authors/80/authorId,authors/80/name,authors/81/authorId,authors/81/name,authors/82/authorId,authors/82/name,authors/83/authorId,authors/83/name,authors/84/authorId,authors/84/name,authors/85/authorId,authors/85/name,authors/86/authorId,authors/86/name,authors/87/authorId,authors/87/name,authors/88/authorId,authors/88/name,authors/89/authorId,authors/89/name,authors/90/authorId,authors/90/name,authors/91/authorId,authors/91/name,authors/92/authorId,authors/92/name,authors/93/authorId,authors/93/name,authors/94/authorId,authors/94/name,authors/95/authorId,authors/95/name,authors/96/authorId,authors/96/name,authors/97/authorId,authors/97/name,authors/98/authorId,authors/98/name,authors/99/authorId,authors/99/name,authors/100/authorId,authors/100/name,authors/101/authorId,authors/101/name,authors/102/authorId,authors/102/name,authors/103/authorId,authors/103/name,authors/104/authorId,authors/104/name,authors/105/authorId,authors/105/name,authors/106/authorId,authors/106/name,authors/107/authorId,authors/107/name,authors/108/authorId,authors/108/name,authors/109/authorId,authors/109/name,authors/110/authorId,authors/110/name,authors/111/authorId,authors/111/name,fieldsOfStudy/4,authors/112/authorId,authors/112/name,authors/113/authorId,authors/113/name,authors/114/authorId,authors/114/name,authors/115/authorId,authors/115/name,authors/116/authorId,authors/116/name,authors/117/authorId,authors/117/name,authors/118/authorId,authors/118/name,authors/119/authorId,authors/119/name,authors/120/authorId,authors/120/name,authors/121/authorId,authors/121/name,authors/122/authorId,authors/122/name,authors/123/authorId,authors/123/name,authors/124/authorId,authors/124/name,authors/125/authorId,authors/125/name,authors/126/authorId,authors/126/name,authors/127/authorId,authors/127/name,authors/128/authorId,authors/128/name,authors/129/authorId,authors/129/name,authors/130/authorId,authors/130/name,authors/131/authorId,authors/131/name,authors/132/authorId,authors/132/name,authors/133/authorId,authors/133/name,authors/134/authorId,authors/134/name,authors/135/authorId,authors/135/name,authors/136/authorId,authors/136/name,authors/137/authorId,authors/137/name,authors/138/authorId,authors/138/name,authors/139/authorId,authors/139/name,authors/140/authorId,authors/140/name,authors/141/authorId,authors/141/name,authors/142/authorId,authors/142/name
1,46200b99c40e8586c8a0f588488ab6414119fb28,https://www.semanticscholar.org/paper/46200b99c40e8586c8a0f588488ab6414119fb28,TensorFlow: A system for large-scale machine learning,"TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous ""parameter server"" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",2016,94,13969,1679,False,Computer Science,2057642721,Mart√≠n Abadi,144758007,P. Barham,2108406634,Jianmin Chen,2545358,Z. Chen,36347083,Andy Davis,49959210,J. Dean,145139947,Matthieu Devin,1780892,S. Ghemawat,2060655766,Geoffrey Irving,2090818,M. Isard,1942300,M. Kudlur,3369421,J. Levenberg,3089272,R. Monga,144375552,Sherry Moore,20154699,D. Murray,32163737,Benoit Steiner,2080690,P. Tucker,2053781980,Vijay Vasudevan,47941411,P. Warden,35078078,M. Wicke,2117163698,Yuan Yu,2108113547,Xiaoqiang Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2,f9c602cc436a9ea2f9e7db48c77d924e09ce3c32,https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32,Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms,"We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL",2017,6,4588,1340,False,Computer Science,145642373,Han Xiao,4565995,Kashif Rasul,2742129,Roland Vollgraf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3,9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d,https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d,TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems,"TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",2016,55,9429,1008,False,Computer Science,2057642721,Mart√≠n Abadi,2078528337,Ashish Agarwal,144758007,P. Barham,2445241,E. Brevdo,2545358,Z. Chen,48738717,C. Citro,32131713,G. Corrado,36347083,Andy Davis,49959210,J. Dean,145139947,Matthieu Devin,1780892,S. Ghemawat,153440022,Ian J. Goodfellow,2064102917,A. Harp,2060655766,Geoffrey Irving,2090818,M. Isard,39978391,Yangqing Jia,1944541,R. J√≥zefowicz,40527594,Lukasz Kaiser,1942300,M. Kudlur,3369421,J. Levenberg,30415265,Dandelion Man√©,3089272,R. Monga,,144375552,Sherry Moore,20154699,D. Murray,37232298,C. Olah,144927151,M. Schuster,1789737,Jonathon Shlens,32163737,Benoit Steiner,1701686,Ilya Sutskever,35210462,Kunal Talwar,2080690,P. Tucker,2657155,Vincent Vanhoucke,2053781980,Vijay Vasudevan,1765169,F. Vi√©gas,1689108,Oriol Vinyals,47941411,P. Warden,145233583,M. Wattenberg,35078078,M. Wicke,2117163698,Yuan Yu,2152198093,Xiaoqiang Zheng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4,f9c990b1b5724e50e5632b94fdb7484ece8a6ce7,https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7,Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting,"The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.",2015,26,4697,738,False,Computer Science,3008587,Xingjian Shi,2192200,Zhourong Chen,49528584,Hao Wang,1739816,D. Yeung,145771919,W. Wong,2183294,W. Woo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5,0090023afc66cd2741568599057f4e82b566137c,https://www.semanticscholar.org/paper/0090023afc66cd2741568599057f4e82b566137c,A Survey on Bias and Fairness in Machine Learning,"With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",2019,176,1360,80,True,Computer Science,51997673,Ninareh Mehrabi,2775559,Fred Morstatter,51884035,N. Saxena,1782658,Kristina Lerman,143728483,A. Galstyan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6,25badc676197a70aaf9911865eb03469e402ba57,https://www.semanticscholar.org/paper/25badc676197a70aaf9911865eb03469e402ba57,Machine learning - a probabilistic perspective,"Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.",2012,1032,7662,976,False,Computer Science,2056417995,K. Murphy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7,168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74,https://www.semanticscholar.org/paper/168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74,Scikit-learn: Machine Learning in Python,"Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",2011,18,48681,3060,False,Computer Science,2570016,Fabian Pedregosa,3025780,G. Varoquaux,1797840,Alexandre Gramfort,52200573,V. Michel,8493461,B. Thirion,2958756,O. Grisel,27257992,Mathieu Blondel,1881041,Gilles Louppe,2780213,P. Prettenhofer,2067827437,Ron Weiss,39571582,Ron J. Weiss,2081469,J. Vanderplas,144720379,Alexandre Passos,3084321,D. Cournapeau,2423884,M. Brucher,35243423,M. Perrot,1710398,E. Duchesnay,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8,2e2089ae76fe914706e6fa90081a79c8fe01611e,https://www.semanticscholar.org/paper/2e2089ae76fe914706e6fa90081a79c8fe01611e,Practical Bayesian Optimization of Machine Learning Algorithms,"The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a ""black art"" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",2012,30,5532,496,False,Computer Science,144108062,Jasper Snoek,1777528,H. Larochelle,1722180,Ryan P. Adams,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9,53b047e503f4c24602f376a774d653f7ed56c024,https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024,Practical Black-Box Attacks against Machine Learning,"Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.",2016,39,2572,211,True,Computer Science,1967156,Nicolas Papernot,144061974,P. Mcdaniel,153440022,Ian J. Goodfellow,1680133,S. Jha,144643812,Z. B. Celik,144231976,A. Swami,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10,5c39e37022661f81f79e481240ed9b175dec6513,https://www.semanticscholar.org/paper/5c39e37022661f81f79e481240ed9b175dec6513,Towards A Rigorous Science of Interpretable Machine Learning,"As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.",2017,63,2204,203,False,Computer Science,1388372395,Finale Doshi-Velez,3351164,Been Kim,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
